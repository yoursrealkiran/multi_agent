{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6TSNWwe080oXkjgYHAc4Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoursrealkiran/multi_agent/blob/main/collab/2_core_components.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Message Types**"
      ],
      "metadata": {
        "id": "fM6AYzGtve55"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1kCVA1ooZ6b"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage, AIMessage"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [AIMessage(content=\"So, you said you were researching ocean mammals?\", name=\"Model\")] # Wrapped as a list and stored in a variable"
      ],
      "metadata": {
        "id": "N7EMYGNyozfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages.append(HumanMessage(content=\"Yes, That's right\", name=\"Kiran\"))"
      ],
      "metadata": {
        "id": "Z2Ze7Uazplmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MK0zTL2KqBYZ",
        "outputId": "e39f7afa-cecd-4796-e715-2e950e8f4fe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[AIMessage(content='So, you said you were researching ocean mammals?', additional_kwargs={}, response_metadata={}, name='Model'),\n",
              " HumanMessage(content=\"Yes, That's right\", additional_kwargs={}, response_metadata={}, name='Kiran')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages.append(AIMessage(content=\"Great, What would you like to learn?\", name=\"Model\"))\n",
        "messages.append(HumanMessage(content=\"I would like to learn about dolphins\", name=\"Kiran\"))"
      ],
      "metadata": {
        "id": "97zXiWwmqH8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLtdtOWgqjPH",
        "outputId": "a9b8331d-9764-41cf-af8a-83bf8e848144"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[AIMessage(content='So, you said you were researching ocean mammals?', additional_kwargs={}, response_metadata={}, name='Model'),\n",
              " HumanMessage(content=\"Yes, That's right\", additional_kwargs={}, response_metadata={}, name='Kiran'),\n",
              " AIMessage(content='Great, What would you like to learn?', additional_kwargs={}, response_metadata={}, name='Model'),\n",
              " HumanMessage(content='I would like to learn about dolphins', additional_kwargs={}, response_metadata={}, name='Kiran')]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for m in messages:\n",
        "    m.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ik-VnYHqkNi",
        "outputId": "a8f7d6f2-69a3-4d88-ccdf-e6bf04392fa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Name: Model\n",
            "\n",
            "So, you said you were researching ocean mammals?\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "Name: Kiran\n",
            "\n",
            "Yes, That's right\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Name: Model\n",
            "\n",
            "Great, What would you like to learn?\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "Name: Kiran\n",
            "\n",
            "I would like to learn about dolphins\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chat Models**"
      ],
      "metadata": {
        "id": "s5jDyXq5vlno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFkohhnKqr-y",
        "outputId": "a36882d0-47ef-47ae-d2a4-d4781304a10e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_groq\n",
            "  Downloading langchain_groq-1.1.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting groq<1.0.0,>=0.30.0 (from langchain_groq)\n",
            "  Downloading groq-0.37.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_groq) (1.2.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain_groq) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain_groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain_groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain_groq) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain_groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain_groq) (4.15.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain_groq) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain_groq) (0.4.59)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain_groq) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain_groq) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain_groq) (9.1.2)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain_groq) (0.12.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq<1.0.0,>=0.30.0->langchain_groq) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain_groq) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain_groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain_groq) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.0->langchain_groq) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain_groq) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain_groq) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain_groq) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain_groq) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq<1.0.0,>=0.30.0->langchain_groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq<1.0.0,>=0.30.0->langchain_groq) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq<1.0.0,>=0.30.0->langchain_groq) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain_groq) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain_groq) (2.5.0)\n",
            "Downloading langchain_groq-1.1.1-py3-none-any.whl (19 kB)\n",
            "Downloading groq-0.37.1-py3-none-any.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq, langchain_groq\n",
            "Successfully installed groq-0.37.1 langchain_groq-1.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"GROQ_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Please enter your GROQ API key:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hd6ttJUvsAov",
        "outputId": "48d071c1-03af-4c54-9b70-9a2cf37873eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter your GROQ API key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq"
      ],
      "metadata": {
        "id": "uTOf8DRQsLTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGroq(\n",
        "    model = \"openai/gpt-oss-20b\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    reasoning_format=\"parsed\",\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        ")"
      ],
      "metadata": {
        "id": "NDpHb1CUsqRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(\"Hi\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HU9pSQQkvX3I",
        "outputId": "90fa9402-69cd-43c8-ae34-60c25b6a0205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Hello! How can I help you today?', additional_kwargs={'reasoning_content': 'The user says \"Hi\". We need to respond politely. Probably a friendly greeting.'}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 72, 'total_tokens': 108, 'completion_time': 0.03776801, 'completion_tokens_details': {'reasoning_tokens': 18}, 'prompt_time': 0.00339129, 'prompt_tokens_details': None, 'queue_time': 0.003205779, 'total_time': 0.0411593}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_d6de37e6be', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019ba2bd-daad-7a40-ad1c-96ef284ced0b-0', usage_metadata={'input_tokens': 72, 'output_tokens': 36, 'total_tokens': 108, 'output_token_details': {'reasoning': 18}})"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chat Model integrates with Message types**"
      ],
      "metadata": {
        "id": "48u7c_7pvryI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tu3MpxYWv4db",
        "outputId": "f5a13ce7-4711-4a0e-f036-7842a7e0af33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='### Dolphins 101 – A Quick Guide to the Ocean’s Most Charming Mammals\\n\\n| Topic | Key Points |\\n|-------|------------|\\n| **What are dolphins?** | Marine mammals in the family *Delphinidae* (the “true dolphins”). They’re part of the order *Cetacea* (whales, porpoises, and dolphins). |\\n| **How many species?** | About **90** recognized species, ranging from the tiny *Pygmy Killer Whale* (≈1\\u202fm) to the massive *Bottlenose Dolphin* (≈4\\u202fm). |\\n| **Where do they live?** | Found in every ocean, from shallow coastal bays to the deep open sea. Some species are highly migratory, while others are more localized. |\\n| **Why are they special?** | • **Intelligence** – brain-to-body ratio comparable to great apes. <br>• **Communication** – complex vocal repertoire, echolocation clicks, whistles, and body language. <br>• **Sociality** – live in pods that can number from a few to several hundred. |\\n\\n---\\n\\n## 1. Taxonomy & Physical Traits\\n\\n| Feature | Typical Range |\\n|---------|---------------|\\n| **Size** | 1–4\\u202fm (3–13\\u202fft) |\\n| **Weight** | 70–1,000\\u202fkg (150–2,200\\u202flb) |\\n| **Lifespan** | 20–60\\u202fyears (varies by species) |\\n| **Body Shape** | Streamlined, torpedo‑shaped, dorsal fin, fluked tail. |\\n| **Skin** | Smooth, often with a thin layer of blubber (5–15\\u202fcm) for insulation. |\\n| **Color** | Usually dark gray or blue‑gray dorsally, lighter ventrally (counter‑shading). Some species have distinctive markings (e.g., the *Spotted Dolphin*). |\\n\\n---\\n\\n## 2. Intelligence & Communication\\n\\n| Aspect | Details |\\n|--------|---------|\\n| **Brain size** | 1–2\\u202f% of body weight; the bottlenose dolphin’s brain is about 1.5\\u202fkg. |\\n| **Cognitive abilities** | Tool use (e.g., sponges to protect snouts), problem solving, self‑recognition in mirrors, complex social learning. |\\n| **Vocal repertoire** | • **Clicks** – used for echolocation. <br>• **Whistles** – individual “signature” sounds (like names). <br>• **Burst pulses** – used in social contexts. |\\n| **Echolocation** | Emits high‑frequency clicks; listens to returning echoes to build a 3‑D map of surroundings. |\\n\\n---\\n\\n## 3. Social Structure\\n\\n| Pod Feature | Example |\\n|-------------|---------|\\n| **Size** | 5–200+ individuals. |\\n| **Roles** | *Alphas* (dominant males or females), *helpers*, *breeders*, *juveniles*. |\\n| **Cooperation** | Hunting in groups, protecting calves, sharing food. |\\n| **Culture** | Distinct “dialects” of whistles and hunting techniques can be passed down generations. |\\n\\n---\\n\\n## 4. Diet & Hunting\\n\\n| Prey | Typical Hunting Technique |\\n|------|---------------------------|\\n| Fish | Pursuit, coordinated “school‑slicing.” |\\n| Squid | Ambush, sometimes using “sponging” to protect snouts. |\\n| Crustaceans | For species like the *Spotted Dolphin*, they use “sponging” or “suction” techniques. |\\n| Small mammals | Rare, but some dolphins will chase seals or sea lions. |\\n\\n---\\n\\n## 5. Reproduction & Life Cycle\\n\\n| Stage | Details |\\n|-------|---------|\\n| **Mating** | Often seasonal; males may form “harems.” |\\n| **Gestation** | 10–12\\u202fmonths (varies by species). |\\n| **Calving** | Calves are born tail‑first, weigh 30–70\\u202fkg, and are weaned after 6–12\\u202fmonths. |\\n| **Longevity** | Bottlenose dolphins can live 40–50\\u202fyears in the wild; some individuals have been recorded over 70\\u202fyears. |\\n\\n---\\n\\n## 6. Conservation Status\\n\\n| Threat | Impact |\\n|--------|--------|\\n| **Bycatch** | Accidental capture in fishing nets. |\\n| **Pollution** | Plastic ingestion, chemical contaminants (PCBs, mercury). |\\n| **Habitat loss** | Coastal development, shipping lanes. |\\n| **Climate change** | Shifts in prey distribution, ocean acidification. |\\n| **Legal protection** | Many species are protected under CITES, the Marine Mammal Protection Act (US), and various national laws. |\\n\\n**IUCN Red List**: Most dolphin species are listed as *Least Concern*, but several (e.g., *Vaquita*, *Ganges River Dolphin*) are *Critically Endangered*.\\n\\n---\\n\\n## 7. Human Interaction\\n\\n| Interaction | Notes |\\n|-------------|-------|\\n| **Research** | Non‑invasive acoustic monitoring, photo‑identification, satellite tagging. |\\n| **Ecotourism** | Whale‑watching tours, dolphin‑watching cruises. |\\n| **Captive Care** | Aquariums and marine parks; ethical debates over captivity. |\\n| **Cultural Significance** | Dolphins appear in myths, folklore, and as symbols of intelligence and playfulness. |\\n\\n---\\n\\n## 8. Fun Facts\\n\\n1. **Speed** – Bottlenose dolphins can reach 35\\u202fkm/h (22\\u202fmph) in short bursts.  \\n2. **Echolocation range** – Up to 1\\u202fkm (0.6\\u202fmi) in clear water.  \\n3. **Play behavior** – They surf waves, play “tag,” and even use tools (sponges).  \\n4. **Human resemblance** – Some dolphins have been observed using “hand‑shakes” with humans, indicating social bonding.  \\n5. **Longevity of memory** – Studies show dolphins can remember individual humans for decades.\\n\\n---\\n\\n## 9. Quick Study Guide\\n\\n| Question | Answer |\\n|----------|--------|\\n| What family do dolphins belong to? | *Delphinidae* |\\n| How many species of dolphins are there? | About 90 |\\n| What is a dolphin’s signature sound? | A unique whistle, often called a “signature whistle.” |\\n| What is the primary hunting technique of bottlenose dolphins? | Cooperative “school‑slicing” of fish. |\\n| Which dolphin species is critically endangered? | *Vaquita* (small porpoise, but often grouped with dolphins). |\\n\\n---\\n\\n### Where to Learn More\\n\\n- **Books**: *“Dolphins: The Science of the World’s Most Intelligent Marine Mammals”* by John B. Heithoff.  \\n- **Documentaries**: *“The Life of Dolphins”* (BBC), *“Dolphin Reef”* (National Geographic).  \\n- **Research Journals**: *Marine Mammal Science*, *Journal of Cetacean Research*.  \\n- **Websites**: NOAA’s Marine Mammal Center, World Wildlife Fund (WWF), IUCN Red List.\\n\\n---\\n\\n**Got a specific question?** Whether you’re curious about a particular species, want to know how dolphins are studied, or are interested in conservation efforts, just let me know!', additional_kwargs={'reasoning_content': 'We need to respond with information about dolphins. The user wants to learn about dolphins. We should provide a comprehensive overview: taxonomy, species, physical characteristics, behavior, intelligence, communication, social structure, habitat, diet, reproduction, conservation status, human interactions, interesting facts. Also maybe mention research topics. Provide citations? Not necessary. Provide engaging content.'}, response_metadata={'token_usage': {'completion_tokens': 1651, 'prompt_tokens': 117, 'total_tokens': 1768, 'completion_time': 1.742949549, 'completion_tokens_details': {'reasoning_tokens': 72}, 'prompt_time': 0.00555928, 'prompt_tokens_details': None, 'queue_time': 0.002877559, 'total_time': 1.748508829}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_d8063b0a5c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019ba2bf-9618-7f93-8f18-61173bc4d939-0', usage_metadata={'input_tokens': 117, 'output_tokens': 1651, 'total_tokens': 1768, 'output_token_details': {'reasoning': 72}})"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = llm.invoke(messages)"
      ],
      "metadata": {
        "id": "Qcoap6CosxxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "QO-j12intdZj",
        "outputId": "4a96cf53-87d5-45bd-f9f8-3fbac06e61cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "langchain_core.messages.ai.AIMessage"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>langchain_core.messages.ai.AIMessage</b><br/>def __init__(content: str | list[str | dict] | None=None, content_blocks: list[types.ContentBlock] | None=None, **kwargs: Any) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/langchain_core/messages/ai.py</a>Message from an AI.\n",
              "\n",
              "An `AIMessage` is returned from a chat model as a response to a prompt.\n",
              "\n",
              "This message represents the output of the model and consists of both\n",
              "the raw output as returned by the model and standardized fields\n",
              "(e.g., tool calls, usage metadata) added by the LangChain framework.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 159);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res.response_metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tsSWs70u7aA",
        "outputId": "2342a317-47d7-48fa-b7e7-b9c78df0dbf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'token_usage': {'completion_tokens': 1620,\n",
              "  'prompt_tokens': 117,\n",
              "  'total_tokens': 1737,\n",
              "  'completion_time': 1.760717597,\n",
              "  'completion_tokens_details': {'reasoning_tokens': 72},\n",
              "  'prompt_time': 0.006576688,\n",
              "  'prompt_tokens_details': None,\n",
              "  'queue_time': 0.007924618,\n",
              "  'total_time': 1.767294285},\n",
              " 'model_name': 'openai/gpt-oss-20b',\n",
              " 'system_fingerprint': 'fp_3417a662f8',\n",
              " 'service_tier': 'on_demand',\n",
              " 'finish_reason': 'stop',\n",
              " 'logprobs': None,\n",
              " 'model_provider': 'groq'}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i_9EXDP0vHn7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}